{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import grad\n",
    "from jax import jit\n",
    "import cvxopt # TODO: speed up via convex approach\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class optimROBD(object):\n",
    "\n",
    "    ''' TODOS: \n",
    "    1) what is prevH_0? A: must create when sending it in\n",
    "    2) how do we do the projection using scipy?\n",
    "    '''\n",
    "\n",
    "    def __init__(self, Cs, p, T, d, prevH, lam=0):\n",
    "        self._lam = lam\n",
    "        self._l1 = lam\n",
    "        self._l2 = 0\n",
    "        self._Cs = np.array(Cs)\n",
    "        self._p = p\n",
    "        self._T = T\n",
    "        self._prevH = prevH\n",
    "        self._yhats = np.ndarray((T, d))\n",
    "        self._d = d\n",
    "\n",
    "\n",
    "    # does a specific instance of oROBD\n",
    "    # h_t comes from the control algorithm\n",
    "    def step(self, v_tminus, h_t, omega_t, t):\n",
    "        prevH = self._prevH\n",
    "\n",
    "        # returns a function of y\n",
    "        prevFunc = self.hittingCost(prevH, v_tminus)\n",
    "\n",
    "        # building out the yhat sequence\n",
    "        self._yhats[t-1, :] = self.robdSub(prevFunc, t-1)\n",
    "\n",
    "        vtilde = self.findSetMin(self.doubleFunc(h_t, t), omega_t)\n",
    "\n",
    "        fhatFunc = self.hittingCost(h_t, vtilde)\n",
    "        self._prevH = h_t\n",
    "\n",
    "        y_t = self.robdSub(fhatFunc, t)\n",
    "\n",
    "        return y_t\n",
    "\n",
    "    #TODO: change if necessary\n",
    "    def doubleFunc(self, h_t, t):\n",
    "        def func(params):\n",
    "            y = params[:self._d]\n",
    "            v = params[self._d:]\n",
    "            return h_t(y - v) + self._lam * self.cost(t)(y)\n",
    "        return func\n",
    "    \n",
    "    #TODO: change if necessary\n",
    "    def constraint(self, omega_t):\n",
    "        def func(params):\n",
    "            y = params[:self._d]\n",
    "            v = params[self._d:]\n",
    "            if tuple(v) in omega_t:\n",
    "                return 0\n",
    "            return 1 #return a non-zero element\n",
    "        return func\n",
    "\n",
    "    ''' To implement from here '''  \n",
    "\n",
    "    #TODO: incorporate projection\n",
    "    def findSetMin(self, function, omega_t):\n",
    "        x0 = (np.random.randn(d), np.random.randn(d))\n",
    "        # constraint: must be in the set omega_t\n",
    "        '''\n",
    "        cons = ({'type': 'eq', 'fun': self.constraint(omega_t)})\n",
    "\n",
    "        result = minimize(function, x0, method = 'SLSQP', constraints=cons)\n",
    "        '''\n",
    "\n",
    "        result = minimize(function, x0, method = 'COBYLA')\n",
    "        if result.success:\n",
    "            fitted_params = np.array(result.x[1]) #want to return v?\n",
    "            return fitted_params\n",
    "        else:\n",
    "            raise ValueError(result.message)\n",
    "    \n",
    "    # Find the d x 1 vector y that minimizes the function parameter\n",
    "    # TODO: change to convex optimizer\n",
    "    def _findMin(self, func):\n",
    "        x0 = np.random.rand(self._d)\n",
    "        res = minimize(func, x0, method='BFGS', options={'disp':False})\n",
    "        return np.array(res.x)\n",
    "\n",
    "    ''' End to implement here'''\n",
    "\n",
    "    # subroutine for ROBD and optimistic ROBD\n",
    "    def robdSub(self, fun, t):\n",
    "        vel = self._findMin(fun)\n",
    "\n",
    "        # below line: find minimum of entire expression with respect to y\n",
    "        out = self._findMin(self.totalCost(fun, vel, t))\n",
    "        return out\n",
    "    \n",
    "    # precondition: v_t must be a numpy array\n",
    "    def totalCost(self, fun, v_t, t):\n",
    "        def func(y):\n",
    "            return fun(y) + self._l1 * self.cost(t)(y) + self._l2 * self.dist(v_t)(y)\n",
    "        return func\n",
    "    \n",
    "    #precondition: yhats, Cs must be numpy arrays\n",
    "    def cost(self, t):\n",
    "        def func (y):\n",
    "            # each element in decisions is a d x 1 vector, and C is dxd (for each time step)\n",
    "\n",
    "            decisions = self._yhats[t - self._p : t]\n",
    "            Cs = self._Cs\n",
    "\n",
    "            summ = np.zeros(self._d)\n",
    "            for i in range(self._p):\n",
    "                C = Cs[i]\n",
    "                summ += np.matmul(C, decisions[self._p-i-1].T) #TODO: check\n",
    "            norm = np.linalg.norm(y - summ)\n",
    "            return (norm**2)/2\n",
    "        return func\n",
    "\n",
    "    def dist(self, v_t):\n",
    "        def func(y):\n",
    "            norm = np.linalg.norm(y-v_t)\n",
    "            return (norm**2)/2\n",
    "        return func\n",
    "\n",
    "    # must be numpy arrays\n",
    "    def hittingCost(self, h, v_t):\n",
    "        def func(y):\n",
    "            return h(y-v_t)\n",
    "        return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.array([[[1,2,3],[1,2,3], [4,5,6]],[[1,1,1], [1,1,1], [1,1,1]]]) # 2 time steps, d = 3\n",
    "p=2\n",
    "d = 3\n",
    "T = 10\n",
    "lam = 0\n",
    "optimizer = optimROBD(Cs, p, T, d, h2, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.50300946, 1.82807014, 1.65204057])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_tminus = np.array([1,2,3])\n",
    "def h2(x):\n",
    "    return np.sum((x-np.array([1,2,3]))**2)-1\n",
    "arrays = np.array([[1,2,3], [2,3,4], [3,4,5]])\n",
    "omega_t = {tuple(row) for row in arrays}\n",
    "\n",
    "optimizer.step(v_tminus, h2, omega_t, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
